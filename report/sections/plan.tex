\chapter{Plan}\label{ch:plan}

Please see table \ref{table:plan} for the weekly breakdown of work.

\rowcolors{2}{gray!25}{white}
\begin{table}
\caption{Weekly breakdown of work to be done.}\label{table:plan}
\begin{tabularx}{155mm}{|>{\setlength\hsize{.2\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{.3\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{1.5\hsize}\setlength\linewidth{\hsize}}X|}
	\rowcolor{gray!50}
\hline
% \multicolumn{3}{|c|}{Classification of the criticel point $(0,0)$ of $x'=Ax,|\mathbf{A}|\not=0$.}\\
% \hline
\centering Weeks & \centering End Date & Tasks \\
\hline

Week 1
&
22 Jan.
&
Understanding the classification task\\
\hline

Week 2
&
29 Jan.
&
\begin{itemize}
\item Understanding the classification task
\item Read about \href{https://canvas.vt.edu/courses/21271/files/folder/2015/Tutorials?preview=390175}{Hadoop streaming using python}
\end{itemize}\\
\hline

Week 3
&
5 Feb.
&
Start online tutorials about Hadoop and Apache Spark.\\
\hline

Week 4
&
12 Feb.
&
Continue online tutorials about Hadoop and Apache Spark.\\
\hline

Week 5
&
19 Feb.
&
\textbf{Phase 1 will include only tweets small data set:}
\begin{itemize}
\item Understanding the classification task
\item Read about Hadoop streaming using python
\end{itemize}\\
\hline

Week 6
&
26 Feb.
&
\begin{itemize}
\item Prepare training data using Solr
\item Build classifier using Apache Spark
\end{itemize}\\
\hline

Week 7
&
4 March
&
\begin{itemize}
\item Build classifier using Apache Spark
\item Get output data format from Solr team
\end{itemize}\\
\hline

Week 8
&
11 March
&
Optimize classifier performance\\
\hline
\end{tabularx}
\end{table}
\newpage
\begin{tabularx}{155mm}{|>{\setlength\hsize{.2\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{.3\hsize}\setlength\linewidth{\hsize}}X|>{\setlength\hsize{1.5\hsize}\setlength\linewidth{\hsize}}X|}
\hline
% \multicolumn{3}{|c|}{Classification of the criticel point $(0,0)$ of $x'=Ax,|\mathbf{A}|\not=0$.}\\
% \hline
Weeks & End Date & Tasks \\
\hline
Week 9
&
18 March
&
\textbf{Phase 2 will include tweets and web pages:} \

\textbf{Once Spark on the cluster is updated to version 1.6 we will do the following:}

\begin{itemize}
\item Run our methodology to classify the tweets on the cluster.
\item Apply the Frequent Pattern methodology on the cleaned pages provided by collection management team.
\item Develop Hbase interface through which the classifier prediction output will be saved on Hbase.
\end{itemize}\\
\hline

Week 10
&
25 March
&
Design an evaluation approach to test and evaluate our methodology. \\
\hline

Week 11
&
1 April
&
Train multiple classifiers and pick the best model per collection. \\
\hline

Week 12
&
8 April
&
More research on Hyper-parameter optimization. Check the feasibility of Integrating hyper parameters optimization library \cite{bergstra2013hyperopt} output with Spark. \\
\hline

Week 13-15
&
TBD
&
Search for known approaches to select the most representative data samples for each collection. Then check whether training a classifier using these data samples will enhance the performance or not. \\
\hline

\end{tabularx}